# cache_manager.py â€” AI ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ ìºì‹œ ê´€ë¦¬ì (ê°œì„  ë²„ì „)

import hashlib
import json
import os
import sqlite3
import threading
import pickle
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from contextlib import contextmanager

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ìºì‹œ ì—”íŠ¸ë¦¬ ë°ì´í„° í´ë˜ìŠ¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class CacheEntry:
    """ìºì‹œ í•­ëª© ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    key: str
    value: Any
    created_at: datetime
    expires_at: Optional[datetime]
    access_count: int = 0
    last_accessed: Optional[datetime] = None
    size_bytes: int = 0

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) ìºì‹œ ë§¤ë‹ˆì € í´ë˜ìŠ¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class CacheManager:
    """AI ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ ìºì‹œ ê´€ë¦¬ì"""
    
    def __init__(self, cache_dir: str = "cache", max_size_mb: int = 100):
        """
        ìºì‹œ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            cache_dir: ìºì‹œ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
            max_size_mb: ìµœëŒ€ ìºì‹œ í¬ê¸° (MB)
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
        self.db_path = self.cache_dir / "cache.db"
        self.max_size_bytes = max_size_mb * 1024 * 1024
        self.lock = threading.RLock()
        
        # ì´ˆê¸°í™” ì‘ì—…
        self._init_database()
        self._cleanup_expired()
        
        print(f"ğŸ“¦ ìºì‹œ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ - ë””ë ‰í† ë¦¬: {self.cache_dir}, ìµœëŒ€ í¬ê¸°: {max_size_mb}MB")
    
    def _init_database(self):
        """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        with self._get_db_connection() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS cache_entries (
                    key TEXT PRIMARY KEY,
                    created_at TIMESTAMP,
                    expires_at TIMESTAMP,
                    access_count INTEGER DEFAULT 0,
                    last_accessed TIMESTAMP,
                    size_bytes INTEGER,
                    file_path TEXT
                )
            """)
            conn.commit()
    
    @contextmanager
    def _get_db_connection(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê´€ë¦¬"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        try:
            yield conn
        finally:
            conn.close()
    
    def _generate_cache_key(self, topic: str, domain: str, query_params: Dict = None) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        cache_data = {
            "topic": topic.lower().strip(),
            "domain": domain.lower().strip(),
            "params": query_params or {}
        }
        cache_string = json.dumps(cache_data, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(cache_string.encode('utf-8')).hexdigest()
    
    def _get_file_path(self, key: str) -> Path:
        """ìºì‹œ íŒŒì¼ ê²½ë¡œ ìƒì„±"""
        return self.cache_dir / f"{key}.pkl"
    
    def get(self, topic: str, domain: str, query_params: Dict = None) -> Optional[str]:
        """
        ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ
        
        Args:
            topic: ê²€ìƒ‰ ì£¼ì œ
            domain: ê²€ìƒ‰ ë„ë©”ì¸
            query_params: ì¶”ê°€ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°
            
        Returns:
            ìºì‹œëœ ê²°ê³¼ ë˜ëŠ” None
        """
        key = self._generate_cache_key(topic, domain, query_params)
        
        with self.lock:
            try:
                with self._get_db_connection() as conn:
                    row = conn.execute(
                        "SELECT * FROM cache_entries WHERE key = ?", (key,)
                    ).fetchone()
                
                if not row:
                    return None
                
                # ë§Œë£Œ í™•ì¸
                if row['expires_at']:
                    expires_at = datetime.fromisoformat(row['expires_at'])
                    if datetime.now() > expires_at:
                        print(f"ğŸ—‘ï¸ ë§Œë£Œëœ ìºì‹œ ì‚­ì œ: {key[:8]}...")
                        self._delete_entry(key)
                        return None
                
                # íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
                file_path = Path(row['file_path'])
                if not file_path.exists():
                    print(f"ğŸ—‘ï¸ íŒŒì¼ ì—†ëŠ” ìºì‹œ ì‚­ì œ: {key[:8]}...")
                    self._delete_entry(key)
                    return None
                
                with open(file_path, 'rb') as f:
                    data = pickle.load(f)
                
                # ì ‘ê·¼ í†µê³„ ì—…ë°ì´íŠ¸
                self._update_access_stats(key)
                
                print(f"ğŸ“¦ ìºì‹œ íˆíŠ¸: {key[:8]}... (ì£¼ì œ: {topic})")
                return data
                
            except Exception as e:
                print(f"âŒ ìºì‹œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
                return None
    
    def set(self, topic: str, domain: str, value: str, 
            expire_hours: int = 24, query_params: Dict = None) -> bool:
        """
        ìºì‹œì— ë°ì´í„° ì €ì¥
        
        Args:
            topic: ê²€ìƒ‰ ì£¼ì œ
            domain: ê²€ìƒ‰ ë„ë©”ì¸
            value: ì €ì¥í•  ê°’
            expire_hours: ë§Œë£Œ ì‹œê°„ (ì‹œê°„)
            query_params: ì¶”ê°€ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°
            
        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        key = self._generate_cache_key(topic, domain, query_params)
        
        with self.lock:
            try:
                # íŒŒì¼ì— ë°ì´í„° ì €ì¥
                file_path = self._get_file_path(key)
                with open(file_path, 'wb') as f:
                    pickle.dump(value, f)
                
                # íŒŒì¼ í¬ê¸° í™•ì¸
                size_bytes = file_path.stat().st_size
                
                # ë°ì´í„°ë² ì´ìŠ¤ì— ë©”íƒ€ë°ì´í„° ì €ì¥
                now = datetime.now()
                expires_at = now + timedelta(hours=expire_hours)
                
                with self._get_db_connection() as conn:
                    conn.execute("""
                        INSERT OR REPLACE INTO cache_entries 
                        (key, created_at, expires_at, access_count, last_accessed, size_bytes, file_path)
                        VALUES (?, ?, ?, 0, ?, ?, ?)
                    """, (key, now.isoformat(), expires_at.isoformat(), 
                          now.isoformat(), size_bytes, str(file_path)))
                    conn.commit()
                
                print(f"ğŸ’¾ ìºì‹œ ì €ì¥: {key[:8]}... (ì£¼ì œ: {topic}, í¬ê¸°: {size_bytes} bytes)")
                
                # ìºì‹œ í¬ê¸° ê´€ë¦¬
                self._manage_cache_size()
                
                return True
                
            except Exception as e:
                print(f"âŒ ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {e}")
                return False
    
    def _update_access_stats(self, key: str):
        """ì ‘ê·¼ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            with self._get_db_connection() as conn:
                conn.execute("""
                    UPDATE cache_entries 
                    SET access_count = access_count + 1, last_accessed = ?
                    WHERE key = ?
                """, (datetime.now().isoformat(), key))
                conn.commit()
        except Exception as e:
            print(f"âŒ ì ‘ê·¼ í†µê³„ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
    
    def _delete_entry(self, key: str):
        """ìºì‹œ í•­ëª© ì‚­ì œ"""
        try:
            with self._get_db_connection() as conn:
                row = conn.execute(
                    "SELECT file_path FROM cache_entries WHERE key = ?", (key,)
                ).fetchone()
                
                if row:
                    file_path = Path(row['file_path'])
                    if file_path.exists():
                        file_path.unlink()
                    
                    conn.execute("DELETE FROM cache_entries WHERE key = ?", (key,))
                    conn.commit()
                    
        except Exception as e:
            print(f"âŒ ìºì‹œ í•­ëª© ì‚­ì œ ì˜¤ë¥˜: {e}")
    
    def _cleanup_expired(self):
        """ë§Œë£Œëœ ìºì‹œ í•­ëª© ì •ë¦¬"""
        try:
            now = datetime.now()
            with self._get_db_connection() as conn:
                expired_entries = conn.execute("""
                    SELECT key, file_path FROM cache_entries 
                    WHERE expires_at < ?
                """, (now.isoformat(),)).fetchall()
                
                for entry in expired_entries:
                    file_path = Path(entry['file_path'])
                    if file_path.exists():
                        file_path.unlink()
                
                # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚­ì œ
                deleted_count = conn.execute(
                    "DELETE FROM cache_entries WHERE expires_at < ?", 
                    (now.isoformat(),)
                ).rowcount
                conn.commit()
                
                if deleted_count > 0:
                    print(f"ğŸ—‘ï¸ ë§Œë£Œëœ ìºì‹œ {deleted_count}ê°œ ì •ë¦¬ ì™„ë£Œ")
                    
        except Exception as e:
            print(f"âŒ ë§Œë£Œëœ ìºì‹œ ì •ë¦¬ ì˜¤ë¥˜: {e}")
    
    def _manage_cache_size(self):
        """ìºì‹œ í¬ê¸° ê´€ë¦¬ (LRU ë°©ì‹)"""
        try:
            with self._get_db_connection() as conn:
                # í˜„ì¬ ìºì‹œ í¬ê¸° í™•ì¸
                total_size = conn.execute(
                    "SELECT SUM(size_bytes) FROM cache_entries"
                ).fetchone()[0] or 0
                
                if total_size <= self.max_size_bytes:
                    return
                
                print(f"ğŸ—‘ï¸ ìºì‹œ í¬ê¸° ì´ˆê³¼ ({total_size / 1024 / 1024:.1f}MB), ì •ë¦¬ ì¤‘...")
                
                # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª©ë¶€í„° ì‚­ì œ (LRU)
                old_entries = conn.execute("""
                    SELECT key, file_path FROM cache_entries 
                    ORDER BY last_accessed ASC
                """).fetchall()
                
                for entry in old_entries:
                    file_path = Path(entry['file_path'])
                    if file_path.exists():
                        file_path.unlink()
                    
                    conn.execute("DELETE FROM cache_entries WHERE key = ?", (entry['key'],))
                    conn.commit()
                    
                    # í¬ê¸° ì¬í™•ì¸
                    current_size = conn.execute(
                        "SELECT SUM(size_bytes) FROM cache_entries"
                    ).fetchone()[0] or 0
                    
                    if current_size <= self.max_size_bytes * 0.8:  # 80%ê¹Œì§€ ì¤„ì´ê¸°
                        break
                
                print(f"âœ… ìºì‹œ í¬ê¸° ì •ë¦¬ ì™„ë£Œ")
                
        except Exception as e:
            print(f"âŒ ìºì‹œ í¬ê¸° ê´€ë¦¬ ì˜¤ë¥˜: {e}")
    
    def clear_all(self):
        """ëª¨ë“  ìºì‹œ ì‚­ì œ"""
        try:
            with self.lock:
                with self._get_db_connection() as conn:
                    entries = conn.execute("SELECT file_path FROM cache_entries").fetchall()
                    
                    for entry in entries:
                        file_path = Path(entry['file_path'])
                        if file_path.exists():
                            file_path.unlink()
                    
                    conn.execute("DELETE FROM cache_entries")
                    conn.commit()
                    
                print("ğŸ—‘ï¸ ëª¨ë“  ìºì‹œ ì‚­ì œ ì™„ë£Œ")
                
        except Exception as e:
            print(f"âŒ ìºì‹œ ì „ì²´ ì‚­ì œ ì˜¤ë¥˜: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ì¡°íšŒ"""
        try:
            with self._get_db_connection() as conn:
                stats = conn.execute("""
                    SELECT 
                        COUNT(*) as total_entries,
                        SUM(size_bytes) as total_size,
                        AVG(access_count) as avg_access_count,
                        MAX(access_count) as max_access_count
                    FROM cache_entries
                """).fetchone()
                
                return {
                    "total_entries": stats['total_entries'] or 0,
                    "total_size_mb": (stats['total_size'] or 0) / 1024 / 1024,
                    "avg_access_count": stats['avg_access_count'] or 0,
                    "max_access_count": stats['max_access_count'] or 0,
                    "max_size_mb": self.max_size_bytes / 1024 / 1024
                }
                
        except Exception as e:
            print(f"âŒ ìºì‹œ í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ì „ì—­ ìºì‹œ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ì „ì—­ ìºì‹œ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
cache_manager = CacheManager()

# ëª¨ë“ˆ ì„í¬íŠ¸ ì‹œ ì •ë³´ ì¶œë ¥
if __name__ == "__main__":
    print("ğŸ“‹ cache_manager.py ì‹¤í–‰ë¨")
    print("ğŸ“¦ ìºì‹œ ë§¤ë‹ˆì € ì¤€ë¹„ ì™„ë£Œ")
    
    # í†µê³„ ì¶œë ¥
    stats = cache_manager.get_stats()
    print(f"ğŸ“Š ìºì‹œ í†µê³„: {stats}")
    
    # í…ŒìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
    test_key = "test_topic"
    test_domain = "test_domain"
    test_value = "í…ŒìŠ¤íŠ¸ ìºì‹œ ë°ì´í„°"
    
    # ì €ì¥ í…ŒìŠ¤íŠ¸
    cache_manager.set(test_key, test_domain, test_value)
    
    # ì¡°íšŒ í…ŒìŠ¤íŠ¸
    result = cache_manager.get(test_key, test_domain)
    print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ê²°ê³¼: {result == test_value}")
    
    # ì •ë¦¬
    cache_manager.clear_all()