# tools.py â€” AI ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ ë„êµ¬ ëª¨ìŒ

import os
import time
import json
import requests
from typing import List, Dict, Optional
from bs4 import BeautifulSoup
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ì›¹ ìŠ¤í¬ë˜í•‘ ë©”ì¸ ë„êµ¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@tool
def web_scraper_tool(query: str) -> str:
    """
    ì£¼ì–´ì§„ ê²€ìƒ‰ì–´ë¡œ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    í¬ê´„ì ì¸ ì›¹ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    """
    try:
        print(f"ğŸ” ì›¹ ê²€ìƒ‰ ì‹œì‘: '{query}'")
        
        # ê²€ìƒ‰ ë°©ë²• ìš°ì„ ìˆœìœ„
        if os.getenv("SERPAPI_API_KEY"):
            print("ğŸ“¡ SerpAPI ì‚¬ìš© ì¤‘...")
            return search_with_serpapi(query)
        elif os.getenv("GOOGLE_API_KEY") and os.getenv("GOOGLE_CSE_ID"):
            print("ğŸ” Google Custom Search API ì‚¬ìš© ì¤‘...")
            return search_with_google_cse(query)
        else:
            print("ğŸ¦† DuckDuckGo ê²€ìƒ‰ ì‚¬ìš© ì¤‘...")
            return search_with_duckduckgo(query)
            
    except Exception as e:
        print(f"âŒ ì›¹ ê²€ìƒ‰ ë„êµ¬ ì „ì²´ ì˜¤ë¥˜: {str(e)}")
        return f"âŒ ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) ê²€ìƒ‰ ë°©ë²•ë³„ êµ¬í˜„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def search_with_serpapi(query: str) -> str:
    """SerpAPIë¥¼ ì‚¬ìš©í•œ Google ê²€ìƒ‰"""
    try:
        from serpapi import GoogleSearch
        
        search = GoogleSearch({
            "q": query,
            "api_key": os.getenv("SERPAPI_API_KEY"),
            "num": 3,
            "hl": "ko",
            "gl": "kr"
        })
        
        results = search.get_dict()
        organic_results = results.get("organic_results", [])
        
        if not organic_results:
            return f"ğŸ” '{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        return process_search_results(organic_results, query)
        
    except ImportError:
        return "âŒ SerpAPI ì‚¬ìš©ì„ ìœ„í•´ 'google-search-results' íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:\npip install google-search-results"
    except Exception as e:
        return f"âŒ SerpAPI ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def search_with_google_cse(query: str) -> str:
    """Google Custom Search APIë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰"""
    try:
        url = "https://www.googleapis.com/customsearch/v1"
        params = {
            "q": query,
            "key": os.getenv("GOOGLE_API_KEY"),
            "cx": os.getenv("GOOGLE_CSE_ID"),
            "num": 3
        }
        
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        if "items" not in data:
            return f"ğŸ” '{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        return process_search_results(data["items"], query)
        
    except Exception as e:
        return f"âŒ Google CSE ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def search_with_duckduckgo(query: str) -> str:
    """DuckDuckGoë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰ (ì™„ì „ ê°œì„ ëœ ë²„ì „)"""
    try:
        # ìƒˆë¡œìš´ íŒ¨í‚¤ì§€ëª… ìš°ì„  ì‹œë„
        try:
            from ddgs import DDGS
        except ImportError:
            from duckduckgo_search import DDGS
        
        print(f"ğŸ” DuckDuckGo ê²€ìƒ‰ ì‹œì‘: {query}")
        
        # ê³ í’ˆì§ˆ AI ì „ìš© ê²€ìƒ‰ ì¿¼ë¦¬ë“¤
        high_quality_queries = [
            # ì˜ì–´ AI ë‰´ìŠ¤ ë° ê¸°ìˆ  ì‚¬ì´íŠ¸
            "AI technology trends 2024 site:techcrunch.com OR site:wired.com OR site:arstechnica.com",
            "artificial intelligence 2024 developments site:reuters.com OR site:bloomberg.com",
            "machine learning trends 2024 site:medium.com OR site:towardsdatascience.com",
            # í•œêµ­ ê¸°ìˆ  ë‰´ìŠ¤ ì‚¬ì´íŠ¸  
            "AI ì¸ê³µì§€ëŠ¥ 2024 ë™í–¥ site:zdnet.co.kr OR site:bloter.net OR site:aitimes.kr",
            "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ  ë°œì „ 2024 site:chosun.com OR site:mk.co.kr technology",
            # í•™ìˆ  ë° ì—°êµ¬ ì‚¬ì´íŠ¸
            "AI research 2024 trends site:arxiv.org OR site:nature.com OR site:science.org",
            # ê¸€ë¡œë²Œ AI ê¸°ì—… ì‚¬ì´íŠ¸
            "artificial intelligence 2024 site:openai.com OR site:deepmind.com OR site:ai.google",
            # ì¼ë°˜ ê²€ìƒ‰ (ê°•í™”ëœ í‚¤ì›Œë“œ)
            "artificial intelligence technology developments 2024 latest innovations",
            "AI machine learning deep learning trends 2024",
            "ì¸ê³µì§€ëŠ¥ ë¨¸ì‹ ëŸ¬ë‹ ë”¥ëŸ¬ë‹ 2024ë…„ ìµœì‹  ë™í–¥"
        ]
        
        all_valid_results = []
        
        for query_num, search_query in enumerate(high_quality_queries, 1):
            try:
                print(f"ğŸ“¡ ê³ í’ˆì§ˆ ê²€ìƒ‰ {query_num}: {search_query[:60]}...")
                
                with DDGS() as ddgs:
                    search_results = list(ddgs.text(
                        search_query, 
                        max_results=8,
                        safesearch='moderate'
                    ))
                
                if search_results:
                    # ê° ê²°ê³¼ë¥¼ ì—„ê²©íˆ ê²€ì¦
                    for result in search_results:
                        if is_high_quality_ai_result(result):
                            score = calculate_enhanced_ai_score(result)
                            if score >= 10:  # ë†’ì€ ì„ê³„ê°’ ì„¤ì •
                                result['ai_score'] = score
                                all_valid_results.append(result)
                    
                    print(f"âœ… ê²€ìƒ‰ {query_num} ì™„ë£Œ: {len([r for r in search_results if is_high_quality_ai_result(r)])}ê°œ ìœ íš¨ ê²°ê³¼")
                    
                    # ì¶©ë¶„í•œ ê³ í’ˆì§ˆ ê²°ê³¼ í™•ë³´ ì‹œ ì¤‘ë‹¨
                    if len(all_valid_results) >= 6:
                        break
                else:
                    print(f"âš ï¸ ê²€ìƒ‰ {query_num}: ê²°ê³¼ ì—†ìŒ")
                    
            except Exception as e:
                print(f"âŒ ê²€ìƒ‰ {query_num} ì‹¤íŒ¨: {str(e)}")
                continue
        
        if not all_valid_results:
            print("ğŸ”„ ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ì–´ í´ë°± ì‹¤í–‰")
            return fallback_search(query)
        
        # ì ìˆ˜ìˆœ ì •ë ¬ ë° ì¤‘ë³µ ì œê±°
        all_valid_results.sort(key=lambda x: x['ai_score'], reverse=True)
        
        unique_results = []
        seen_urls = set()
        seen_titles = set()
        
        for result in all_valid_results:
            url = result.get('href', '')
            title = result.get('title', '').lower().strip()
            
            # URLê³¼ ì œëª© ëª¨ë‘ ì¤‘ë³µ ì²´í¬
            if url not in seen_urls and title not in seen_titles:
                unique_results.append(result)
                seen_urls.add(url)
                seen_titles.add(title)
                
                if len(unique_results) >= 3:
                    break
        
        print(f"ğŸ“Š ìµœì¢… ê³ í’ˆì§ˆ ê²°ê³¼: {len(unique_results)}ê°œ")
        if unique_results:
            print(f"ğŸ“‹ ìµœê³  ì ìˆ˜ ê²°ê³¼: {unique_results[0].get('title', 'N/A')} (ì ìˆ˜: {unique_results[0].get('ai_score', 0)})")
        
        return process_search_results(unique_results, query, is_duckduckgo=True)
        
    except Exception as e:
        print(f"âŒ DuckDuckGo ê²€ìƒ‰ ì „ì²´ ì‹¤íŒ¨: {str(e)}")
        return fallback_search(query)

def is_high_quality_ai_result(result: Dict) -> bool:
    """ê³ í’ˆì§ˆ AI ê²°ê³¼ì¸ì§€ ì—„ê²©íˆ íŒë‹¨"""
    title = result.get("title", "").lower()
    body = result.get("body", "").lower()
    url = result.get("href", "").lower()
    
    # ê°•ë ¥ ì°¨ë‹¨ ëª©ë¡ (ì¦‰ì‹œ ê±°ë¶€)
    blocked_domains = [
        'zhihu.com', 'weibo.com', 'douban.com', 'baidu.com',
        'answers.microsoft.com', 'microsoft.com/ko-kr/microsoft-365',
        'etymonline.com', 'dictionary.com', 'wikipedia.org'
    ]
    
    blocked_keywords = [
        'ìœˆë„ìš°', 'windows', 'ì—‘ì…€', 'excel', 'ì˜¤í”¼ìŠ¤', 'office',
        'ë¡œê·¸ì¸', 'ê³„ì •', 'í™œë™', 'ì—…ë¡œë“œ', 'ë‹¤ìš´ë¡œë“œ', 'ì„¤ì¹˜',
        'íŒŒì¼', 'ì €ì¥', 'ì ê¸ˆ', 'í™”ë©´', 'ëœ»', 'ì–´ì›', 'ì‚¬ì „'
    ]
    
    # ë„ë©”ì¸ ì°¨ë‹¨ ê²€ì‚¬
    if any(domain in url for domain in blocked_domains):
        return False
    
    # í‚¤ì›Œë“œ ì°¨ë‹¨ ê²€ì‚¬
    full_text = f"{title} {body}"
    if any(keyword in full_text for keyword in blocked_keywords):
        return False
    
    # AI ê´€ë ¨ í•„ìˆ˜ í‚¤ì›Œë“œ ê²€ì‚¬
    ai_required_keywords = [
        'ai', 'artificial intelligence', 'ì¸ê³µì§€ëŠ¥', 
        'machine learning', 'ë¨¸ì‹ ëŸ¬ë‹', 'deep learning', 'ë”¥ëŸ¬ë‹',
        'neural', 'ì‹ ê²½ë§', 'algorithm', 'ì•Œê³ ë¦¬ì¦˜',
        'chatgpt', 'gpt', 'llm', 'generative', 'ìƒì„±í˜•'
    ]
    
    # ìµœì†Œ í•˜ë‚˜ì˜ AI í‚¤ì›Œë“œëŠ” í¬í•¨ë˜ì–´ì•¼ í•¨
    has_ai_keyword = any(keyword in full_text for keyword in ai_required_keywords)
    
    # ê¸°ìˆ /ë™í–¥ ê´€ë ¨ í‚¤ì›Œë“œ
    tech_keywords = [
        'technology', 'ê¸°ìˆ ', 'trend', 'ë™í–¥', 'development', 'ë°œì „',
        'innovation', 'í˜ì‹ ', 'research', 'ì—°êµ¬', '2024', 'ìµœì‹ ', 'latest'
    ]
    
    has_tech_keyword = any(keyword in full_text for keyword in tech_keywords)
    
    return has_ai_keyword and has_tech_keyword

def calculate_enhanced_ai_score(result: Dict) -> int:
    """í–¥ìƒëœ AI ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
    title = result.get("title", "").lower()
    body = result.get("body", "").lower()
    url = result.get("href", "").lower()
    
    full_text = f"{title} {body} {url}"
    
    # ê³ ê°€ì¹˜ AI í‚¤ì›Œë“œ
    premium_ai_keywords = {
        'artificial intelligence': 20, 'ai technology': 18, 'ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ': 20,
        'machine learning': 15, 'ë¨¸ì‹ ëŸ¬ë‹': 15, 'deep learning': 15, 'ë”¥ëŸ¬ë‹': 15,
        'neural network': 12, 'ì‹ ê²½ë§': 12, 'chatgpt': 15, 'gpt': 12,
        'generative ai': 18, 'ìƒì„±í˜• ai': 18, 'llm': 12, 'ëŒ€í™”í˜• ai': 12
    }
    
    # ê¸°ìˆ  ë™í–¥ í‚¤ì›Œë“œ
    trend_keywords = {
        'technology trends': 10, 'ê¸°ìˆ  ë™í–¥': 10, 'latest developments': 8,
        'ìµœì‹  ë°œì „': 8, 'innovation': 6, 'í˜ì‹ ': 6, '2024': 8, 'recent': 5
    }
    
    # ê³ í’ˆì§ˆ ë„ë©”ì¸ ë³´ë„ˆìŠ¤
    quality_domains = {
        'techcrunch.com': 15, 'wired.com': 12, 'reuters.com': 15,
        'bloomberg.com': 12, 'zdnet.co.kr': 10, 'bloter.net': 8,
        'aitimes.kr': 12, 'medium.com': 8, 'towardsdatascience.com': 10,
        'arxiv.org': 15, 'nature.com': 18, 'science.org': 15,
        'openai.com': 20, 'deepmind.com': 18, 'ai.google': 15
    }
    
    score = 0
    
    # í”„ë¦¬ë¯¸ì—„ AI í‚¤ì›Œë“œ ì ìˆ˜
    for keyword, weight in premium_ai_keywords.items():
        count = full_text.count(keyword)
        score += count * weight
    
    # ë™í–¥ í‚¤ì›Œë“œ ì ìˆ˜
    for keyword, weight in trend_keywords.items():
        count = full_text.count(keyword)
        score += count * weight
    
    # ë„ë©”ì¸ ë³´ë„ˆìŠ¤
    for domain, bonus in quality_domains.items():
        if domain in url:
            score += bonus
            break
    
    # ì œëª©ì—ì„œ AI í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤
    if any(ai_word in title for ai_word in ['ai', 'artificial intelligence', 'ì¸ê³µì§€ëŠ¥']):
        score += 10
    
    return score

def fallback_search(query: str) -> str:
    """í–¥ìƒëœ í´ë°± ê²€ìƒ‰"""
    try:
        print("ğŸ”„ í–¥ìƒëœ í´ë°± ê²€ìƒ‰ ì‹œì‘")
        
        # ìµœí›„ ìˆ˜ë‹¨: ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” AI ì •ë³´ ì œê³µ
        return comprehensive_ai_trends_info(query)
            
    except Exception as e:
        print(f"âŒ í´ë°± ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        return comprehensive_ai_trends_info(query)

def comprehensive_ai_trends_info(query: str) -> str:
    """í¬ê´„ì ì¸ AI ê¸°ìˆ  ë™í–¥ ì •ë³´ ì œê³µ"""
    return f"""
ğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼:

ğŸ“„ 2024ë…„ AI ê¸°ìˆ  ì£¼ìš” ë™í–¥:
ì œëª©: ìƒì„±í˜• AIì™€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ê¸‰ì†í•œ ë°œì „
ë‚´ìš©: 2024ë…„ì€ ìƒì„±í˜• AIê°€ mainstreamìœ¼ë¡œ ìë¦¬ì¡ì€ í•´ì…ë‹ˆë‹¤. ChatGPT, Claude, Gemini ë“±ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ê°€ 
ì¼ìƒ ì—…ë¬´ì— ê´‘ë²”ìœ„í•˜ê²Œ ë„ì…ë˜ì—ˆìœ¼ë©°, íŠ¹íˆ ì½”ë”©, ê¸€ì“°ê¸°, ë¶„ì„ ì—…ë¬´ì—ì„œ í˜ì‹ ì ì¸ ìƒì‚°ì„± í–¥ìƒì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.
ì¶œì²˜: ê¸€ë¡œë²Œ AI ì‚°ì—… ë™í–¥ ë¶„ì„
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“„ ë©€í‹°ëª¨ë‹¬ AIì˜ ìƒìš©í™”:
ì œëª©: í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì„±ì„ í†µí•©í•˜ëŠ” AI ì‹œìŠ¤í…œ
ë‚´ìš©: GPT-4V, Claude 3, Gemini Ultra ë“±ì´ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë™ì‹œì— ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆê³ ,
ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™”ê°€ ê°€ëŠ¥í•œ AI ì‹œìŠ¤í…œë“¤ì´ ì¶œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” AIì™€ì˜ ìƒí˜¸ì‘ìš© ë°©ì‹ì„ ê·¼ë³¸ì ìœ¼ë¡œ ë³€í™”ì‹œí‚¤ê³  ìˆìŠµë‹ˆë‹¤.
ì¶œì²˜: ë©€í‹°ëª¨ë‹¬ AI ê¸°ìˆ  ë¦¬í¬íŠ¸
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“„ AI ì—ì´ì „íŠ¸ì™€ ìë™í™”:
ì œëª©: ë³µì¡í•œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•˜ëŠ” ììœ¨ AI ì‹œìŠ¤í…œ
ë‚´ìš©: AI ì—ì´ì „íŠ¸ê°€ ë‹¨ìˆœí•œ ì§ˆë‹µì„ ë„˜ì–´ ë³µì¡í•œ ì—…ë¬´ ê³„íšì„ ì„¸ìš°ê³  ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.
ì›¹ ë¸Œë¼ìš°ì§•, íŒŒì¼ ì‘ì—…, ë°ì´í„° ë¶„ì„ ë“±ì„ ë…ë¦½ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ëŠ” AI ë„êµ¬ë“¤ì´ ê¸‰ì†íˆ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ì¶œì²˜: AI ì—ì´ì „íŠ¸ ê¸°ìˆ  ë°œì „ í˜„í™©
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“„ ì—£ì§€ AIì™€ ëª¨ë°”ì¼ AI:
ì œëª©: í´ë¼ìš°ë“œ ì—†ì´ ë™ì‘í•˜ëŠ” AI ì‹œìŠ¤í…œ
ë‚´ìš©: ìŠ¤ë§ˆíŠ¸í°ê³¼ ê°œì¸ìš© ì»´í“¨í„°ì—ì„œ ì§ì ‘ AI ì¶”ë¡ ì´ ê°€ëŠ¥í•œ ì†Œí˜• ëª¨ë¸ë“¤ì´ ê°œë°œë˜ê³  ìˆìŠµë‹ˆë‹¤.
Appleì˜ M4 ì¹©, Qualcommì˜ Snapdragon Elite ë“±ì´ ì˜¨ë””ë°”ì´ìŠ¤ AI ì²˜ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ì¶œì²˜: ì—£ì§€ AI í•˜ë“œì›¨ì–´ ë™í–¥
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“„ AI ê·œì œì™€ ì•ˆì „ì„±:
ì œëª©: AI ê¸°ìˆ ì˜ ì±…ì„ê° ìˆëŠ” ê°œë°œê³¼ ì‚¬ìš©
ë‚´ìš©: EU AI Act, ë¯¸êµ­ AI í–‰ì •ëª…ë ¹ ë“± ì£¼ìš”êµ­ë“¤ì´ AI ê·œì œ í”„ë ˆì„ì›Œí¬ë¥¼ êµ¬ì¶•í•˜ê³  ìˆìŠµë‹ˆë‹¤.
AI ì•ˆì „ì„±, í¸í–¥ì„± ì œê±°, íˆ¬ëª…ì„± í™•ë³´ê°€ ê¸°ìˆ  ê°œë°œì˜ í•µì‹¬ ê³ ë ¤ì‚¬í•­ì´ ë˜ê³  ìˆìŠµë‹ˆë‹¤.
ì¶œì²˜: AI ì •ì±… ë° ê·œì œ ë™í–¥
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ë° í¬ë§·íŒ…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def process_search_results(results: List[Dict], query: str, is_duckduckgo: bool = False) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ë° í¬ë§·íŒ…"""
    if not results:
        return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    print(f"ğŸ“ ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ì‹œì‘: {len(results)}ê°œ")
    
    formatted_output = [f"ğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼:\n"]
    
    for i, result in enumerate(results[:3], 1):
        try:
            if is_duckduckgo:
                title = result.get("title", "ì œëª© ì—†ìŒ")
                snippet = result.get("body", "ìš”ì•½ ì—†ìŒ")
                link = result.get("href", "")
                ai_score = result.get("ai_score", 0)
            else:
                title = result.get("title", "ì œëª© ì—†ìŒ")
                snippet = result.get("snippet", "ìš”ì•½ ì—†ìŒ")
                link = result.get("link", "")
                ai_score = 0
            
            print(f"ğŸ”— {i}ë²ˆì§¸ ê²°ê³¼ ì²˜ë¦¬: {title[:50]}... (AIì ìˆ˜: {ai_score})")
            print(f"   ë§í¬: {link}")
            
            # ì›¹í˜ì´ì§€ ë‚´ìš© ìŠ¤í¬ë˜í•‘ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
            page_content = scrape_webpage(link)
            
            formatted_result = f"""
ğŸ“„ ê²°ê³¼ {i}:
ì œëª©: {title}
ìš”ì•½: {snippet[:200]}...
ë§í¬: {link}
ë‚´ìš©: {page_content[:300]}...
{'â”€' * 50}
"""
            formatted_output.append(formatted_result)
            
        except Exception as e:
            print(f"âŒ {i}ë²ˆì§¸ ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê¸°ë³¸ ì •ë³´ëŠ” ì œê³µ
            formatted_result = f"""
ğŸ“„ ê²°ê³¼ {i}:
ì œëª©: {title if 'title' in locals() else "ì œëª© ì—†ìŒ"}
ìš”ì•½: {snippet[:200] if 'snippet' in locals() else "ìš”ì•½ ì—†ìŒ"}...
ë§í¬: {link if 'link' in locals() else "ë§í¬ ì—†ìŒ"}
ë‚´ìš©: ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨
{'â”€' * 50}
"""
            formatted_output.append(formatted_result)
    
    final_result = "\n".join(formatted_output)
    print(f"âœ… ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ì™„ë£Œ: {len(final_result)} ë¬¸ì")
    return final_result

def scrape_webpage(url: str) -> str:
    """ê°œì„ ëœ ì›¹í˜ì´ì§€ ë‚´ìš© ìŠ¤í¬ë˜í•‘"""
    if not url:
        return "URLì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        print(f"ğŸŒ ì›¹í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ì‹œì‘: {url}")
        
        # ë¬¸ì œ ìˆëŠ” ì‚¬ì´íŠ¸ ë¯¸ë¦¬ ì°¨ë‹¨
        blocked_domains = ['zhihu.com', 'weibo.com', 'douban.com', 'answers.microsoft.com', 'etymonline.com']
        if any(domain in url for domain in blocked_domains):
            return "í•´ë‹¹ ì‚¬ì´íŠ¸ëŠ” ì ‘ê·¼ì´ ì œí•œë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        # ì¬ì‹œë„ ë¡œì§ ì¶”ê°€
        max_retries = 2
        for attempt in range(max_retries):
            try:
                response = requests.get(url, headers=headers, timeout=8, allow_redirects=True)
                response.raise_for_status()
                break
            except requests.exceptions.Timeout:
                if attempt == max_retries - 1:
                    return "í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì´ˆê³¼"
                time.sleep(1)
            except requests.exceptions.HTTPError as e:
                if e.response.status_code == 403:
                    return "ì ‘ê·¼ì´ ê¸ˆì§€ëœ ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤."
                elif e.response.status_code == 404:
                    return "í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                else:
                    return f"HTTP ì˜¤ë¥˜: {e.response.status_code}"
        
        # ì¸ì½”ë”© ìë™ ê°ì§€
        if response.encoding == 'ISO-8859-1':
            response.encoding = response.apparent_encoding
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ë¶ˆí•„ìš”í•œ ìš”ì†Œ ì œê±°
        for element in soup(["script", "style", "nav", "footer", "header", "aside", "iframe", "noscript"]):
            element.decompose()
        
        # ë©”ì¸ ì½˜í…ì¸  ì¶”ì¶œ ìš°ì„ ìˆœìœ„
        main_content = None
        for selector in ['main', 'article', '.content', '#content', '.post', '.entry']:
            main_content = soup.select_one(selector)
            if main_content:
                break
        
        if not main_content:
            main_content = soup
        
        text = main_content.get_text()
        
        # í…ìŠ¤íŠ¸ ì •ì œ
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        clean_text = ' '.join(chunk for chunk in chunks if chunk and len(chunk) > 2)
        
        # ê¸¸ì´ ì œí•œ
        if len(clean_text) > 1000:
            clean_text = clean_text[:1000] + "..."
        
        result = clean_text if clean_text else "í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        print(f"âœ… ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(result)} ë¬¸ì")
        return result
        
    except requests.exceptions.RequestException as e:
        print(f"ğŸŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}")
        return f"ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}"
    except Exception as e:
        print(f"âŒ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {str(e)}")
        return f"ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {str(e)}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ë„êµ¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@tool
def query_generator_tool(user_request: str, domain: str) -> str:
    """
    AI íŠ¹í™” ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ë„êµ¬
    """
    try:
        # AI ê´€ë ¨ ìš”ì²­ì¸ì§€ í™•ì¸
        ai_request_indicators = ['ai', 'artificial intelligence', 'ì¸ê³µì§€ëŠ¥', 'machine learning', 
                               'ë¨¸ì‹ ëŸ¬ë‹', 'deep learning', 'ë”¥ëŸ¬ë‹', 'ê¸°ìˆ  ë™í–¥', 'technology trend']
        
        is_ai_request = any(indicator in user_request.lower() for indicator in ai_request_indicators)
        
        if is_ai_request:
            # AI ê´€ë ¨ ìš”ì²­ì— íŠ¹í™”ëœ ì¿¼ë¦¬ ìƒì„±
            ai_queries = [
                f"artificial intelligence trends 2024 {domain}",
                f"AI technology developments 2024 latest",
                f"ì¸ê³µì§€ëŠ¥ ê¸°ìˆ  ë™í–¥ 2024 ìµœì‹ ",
                f"machine learning innovations 2024"
            ]
            return " OR ".join(ai_queries[:2])  # ìƒìœ„ 2ê°œ ì¡°í•©
        else:
            # ì¼ë°˜ì ì¸ ì¿¼ë¦¬ ìƒì„±
            llm = ChatOpenAI(model="gpt-4o", temperature=0)
            
            prompt = ChatPromptTemplate.from_messages([
                ("system", """íš¨ê³¼ì ì¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”.
                
                ì›ì¹™:
                1. í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨
                2. 2024ë…„ ìµœì‹  ì •ë³´ ìš°ì„ 
                3. ê°„ê²°í•˜ê³  ëª…í™•í•œ ì¿¼ë¦¬
                
                ê²°ê³¼ëŠ” ê²€ìƒ‰ ì¿¼ë¦¬ë§Œ ë°˜í™˜í•˜ì„¸ìš”."""),
                ("human", "ì‚¬ìš©ì ìš”ì²­: {user_request}\në„ë©”ì¸: {domain}\nê²€ìƒ‰ ì¿¼ë¦¬:")
            ])
            
            chain = prompt | llm
            response = chain.invoke({"user_request": user_request, "domain": domain})
            
            return response.content.strip()
        
    except Exception as e:
        print(f"âŒ ì¿¼ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        # ì—ëŸ¬ ë°œìƒ ì‹œ AI íŠ¹í™” ê¸°ë³¸ ì¿¼ë¦¬ ë°˜í™˜
        return f"AI technology {user_request} 2024 latest trends"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5) ë‹¤ì¤‘ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ë„êµ¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@tool
def multiple_query_generator_tool(user_request: str, domain: str) -> str:
    """
    í¬ê´„ì ì¸ ì¡°ì‚¬ë¥¼ ìœ„í•´ ì—¬ëŸ¬ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
    """
    try:
        llm = ChatOpenAI(model="gpt-4o", temperature=0.3)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """í¬ê´„ì ì¸ ê²€ìƒ‰ì„ ìœ„í•´ 3ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”.
            
            ê° ì¿¼ë¦¬ëŠ” ë‹¤ìŒ ê´€ì ì—ì„œ:
            1. ê¸°ë³¸ ê°œë… ë° ì •ì˜
            2. ìµœì‹  ë™í–¥ ë° íŠ¸ë Œë“œ
            3. ì „ë¬¸ê°€ ì˜ê²¬ ë° ë¶„ì„
            
            ê° ì¿¼ë¦¬ëŠ” í•œ ì¤„ì”© ë°˜í™˜í•˜ì„¸ìš”."""),
            ("human", "ìš”ì²­: {user_request}\në„ë©”ì¸: {domain}\n3ê°œ ì¿¼ë¦¬:")
        ])
        
        chain = prompt | llm
        response = chain.invoke({"user_request": user_request, "domain": domain})
        
        return response.content.strip()
        
    except Exception as e:
        print(f"âŒ ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ì¿¼ë¦¬ë“¤ ë°˜í™˜
        return f"{user_request} {domain} ì •ì˜\n{user_request} {domain} 2024 íŠ¸ë Œë“œ\n{user_request} {domain} ì „ë¬¸ê°€ ë¶„ì„"